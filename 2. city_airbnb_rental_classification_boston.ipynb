{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime as dt     \n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pwd = os.getcwd()\n",
    "city = 'boston'\n",
    "listings = pd.read_csv(pwd + '/' + city +'/listings_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_since_days</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>...</th>\n",
       "      <th>review_count_2016</th>\n",
       "      <th>booked_nights</th>\n",
       "      <th>no_review</th>\n",
       "      <th>review_above_avg</th>\n",
       "      <th>review_above_75</th>\n",
       "      <th>review_above_90</th>\n",
       "      <th>rental_above_avg</th>\n",
       "      <th>rental_above_75</th>\n",
       "      <th>rental_above_90</th>\n",
       "      <th>avg_nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.394000e+03</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.937086e+06</td>\n",
       "      <td>1342.718881</td>\n",
       "      <td>90.853801</td>\n",
       "      <td>85.735589</td>\n",
       "      <td>0.083124</td>\n",
       "      <td>0.996658</td>\n",
       "      <td>0.750209</td>\n",
       "      <td>42.341695</td>\n",
       "      <td>-71.086112</td>\n",
       "      <td>2.879282</td>\n",
       "      <td>...</td>\n",
       "      <td>9.324979</td>\n",
       "      <td>29.028822</td>\n",
       "      <td>0.520050</td>\n",
       "      <td>0.271930</td>\n",
       "      <td>0.248120</td>\n",
       "      <td>0.248120</td>\n",
       "      <td>0.248120</td>\n",
       "      <td>0.248120</td>\n",
       "      <td>0.098580</td>\n",
       "      <td>3.557644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.613953e+06</td>\n",
       "      <td>586.136343</td>\n",
       "      <td>14.553342</td>\n",
       "      <td>19.358405</td>\n",
       "      <td>0.276128</td>\n",
       "      <td>0.057723</td>\n",
       "      <td>0.432982</td>\n",
       "      <td>0.025122</td>\n",
       "      <td>0.031814</td>\n",
       "      <td>1.650655</td>\n",
       "      <td>...</td>\n",
       "      <td>17.253925</td>\n",
       "      <td>52.433011</td>\n",
       "      <td>0.499702</td>\n",
       "      <td>0.445047</td>\n",
       "      <td>0.432012</td>\n",
       "      <td>0.432012</td>\n",
       "      <td>0.432012</td>\n",
       "      <td>0.432012</td>\n",
       "      <td>0.298159</td>\n",
       "      <td>2.397462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.353000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.235942</td>\n",
       "      <td>-71.179069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.828520e+06</td>\n",
       "      <td>893.250000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.331563</td>\n",
       "      <td>-71.108770</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.382542e+06</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.345197</td>\n",
       "      <td>-71.080166</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.239868e+06</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.357978</td>\n",
       "      <td>-71.063298</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.689904e+06</td>\n",
       "      <td>3099.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.397051</td>\n",
       "      <td>-70.987107</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  host_since_days  host_response_rate  \\\n",
       "count  2.394000e+03      2394.000000         2394.000000   \n",
       "mean   4.937086e+06      1342.718881           90.853801   \n",
       "std    2.613953e+06       586.136343           14.553342   \n",
       "min    3.353000e+03         0.000000            7.000000   \n",
       "25%    2.828520e+06       893.250000           87.000000   \n",
       "50%    5.382542e+06      1180.000000          100.000000   \n",
       "75%    7.239868e+06      1683.000000          100.000000   \n",
       "max    8.689904e+06      3099.000000          100.000000   \n",
       "\n",
       "       host_acceptance_rate  host_is_superhost  host_has_profile_pic  \\\n",
       "count           2394.000000        2394.000000           2394.000000   \n",
       "mean              85.735589           0.083124              0.996658   \n",
       "std               19.358405           0.276128              0.057723   \n",
       "min                0.000000           0.000000              0.000000   \n",
       "25%               76.000000           0.000000              1.000000   \n",
       "50%               95.000000           0.000000              1.000000   \n",
       "75%              100.000000           0.000000              1.000000   \n",
       "max              100.000000           1.000000              1.000000   \n",
       "\n",
       "       host_identity_verified     latitude    longitude  accommodates  \\\n",
       "count             2394.000000  2394.000000  2394.000000   2394.000000   \n",
       "mean                 0.750209    42.341695   -71.086112      2.879282   \n",
       "std                  0.432982     0.025122     0.031814      1.650655   \n",
       "min                  0.000000    42.235942   -71.179069      1.000000   \n",
       "25%                  1.000000    42.331563   -71.108770      2.000000   \n",
       "50%                  1.000000    42.345197   -71.080166      2.000000   \n",
       "75%                  1.000000    42.357978   -71.063298      4.000000   \n",
       "max                  1.000000    42.397051   -70.987107     14.000000   \n",
       "\n",
       "          ...       review_count_2016  booked_nights    no_review  \\\n",
       "count     ...             2394.000000    2394.000000  2394.000000   \n",
       "mean      ...                9.324979      29.028822     0.520050   \n",
       "std       ...               17.253925      52.433011     0.499702   \n",
       "min       ...                0.000000       0.000000     0.000000   \n",
       "25%       ...                0.000000       0.000000     0.000000   \n",
       "50%       ...                0.000000       0.000000     1.000000   \n",
       "75%       ...               11.000000      36.000000     1.000000   \n",
       "max       ...              116.000000     348.000000     1.000000   \n",
       "\n",
       "       review_above_avg  review_above_75  review_above_90  rental_above_avg  \\\n",
       "count       2394.000000      2394.000000      2394.000000       2394.000000   \n",
       "mean           0.271930         0.248120         0.248120          0.248120   \n",
       "std            0.445047         0.432012         0.432012          0.432012   \n",
       "min            0.000000         0.000000         0.000000          0.000000   \n",
       "25%            0.000000         0.000000         0.000000          0.000000   \n",
       "50%            0.000000         0.000000         0.000000          0.000000   \n",
       "75%            1.000000         0.000000         0.000000          0.000000   \n",
       "max            1.000000         1.000000         1.000000          1.000000   \n",
       "\n",
       "       rental_above_75  rental_above_90   avg_nights  \n",
       "count      2394.000000      2394.000000  2394.000000  \n",
       "mean          0.248120         0.098580     3.557644  \n",
       "std           0.432012         0.298159     2.397462  \n",
       "min           0.000000         0.000000     3.000000  \n",
       "25%           0.000000         0.000000     3.000000  \n",
       "50%           0.000000         0.000000     3.000000  \n",
       "75%           0.000000         0.000000     3.000000  \n",
       "max           1.000000         1.000000    60.000000  \n",
       "\n",
       "[8 rows x 68 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "32.0\n"
     ]
    }
   ],
   "source": [
    "listings['churn'] = listings['available_count_2017'].apply(lambda x: 1 if x == 0 else 0)\n",
    "listings['churn'].describe()\n",
    "listings['no_review'] = listings['review_count_2016'].apply(lambda x: 1 if x == 0 else 0)\n",
    "review_avg_2016 = listings['review_count_2016'].mean()\n",
    "listings['review_above_avg'] = listings['review_count_2016'].apply(lambda x: 1 if x > review_avg_2016 else 0)\n",
    "review_75_2016 = np.percentile(listings['review_count_2016'],75)\n",
    "review_90_2016 = np.percentile(listings['review_count_2016'],90)\n",
    "listings['review_above_75'] = listings['review_count_2016'].apply(lambda x: 1 if x > review_90_2016 else 0)\n",
    "print(review_75_2016)\n",
    "print(review_90_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 excellent, 0 normal, -1 bad\n",
    "def rental_category(listings):\n",
    "    if listings['rental_above_90'] == 1:\n",
    "        val = 1\n",
    "    elif listings['rental_above_75'] == 1:\n",
    "        val = 0  \n",
    "    else:\n",
    "        val = -1\n",
    "    return val\n",
    "listings['rental_category']=listings.apply(rental_category,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 77)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings[listings['rental_category'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 77)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings[listings['rental_category'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795, 77)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings[listings['rental_category'] == -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33370473537604456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(236+363)/1795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'host_since_days',\n",
       " 'host_response_time',\n",
       " 'host_response_rate',\n",
       " 'host_acceptance_rate',\n",
       " 'host_is_superhost',\n",
       " 'host_has_profile_pic',\n",
       " 'host_identity_verified',\n",
       " 'neighbourhood',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'bed_type',\n",
       " 'price',\n",
       " 'security_deposit',\n",
       " 'cleaning_fee',\n",
       " 'guests_included',\n",
       " 'extra_people',\n",
       " 'minimum_nights',\n",
       " 'maximum_nights',\n",
       " 'calendar_updated',\n",
       " 'availability_30',\n",
       " 'availability_60',\n",
       " 'availability_90',\n",
       " 'availability_365',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'instant_bookable',\n",
       " 'cancellation_policy',\n",
       " 'require_guest_profile_picture',\n",
       " 'require_guest_phone_verification',\n",
       " 'reviews_per_month',\n",
       " 'AirConditioning',\n",
       " 'BuzzerWirelessIntercom',\n",
       " 'CableTV',\n",
       " 'CarbonMonoxideDetector',\n",
       " 'Dryer',\n",
       " 'ElevatorinBuilding',\n",
       " 'Essentials',\n",
       " 'FamilyKidFriendly',\n",
       " 'FireExtinguisher',\n",
       " 'FirstAidKit',\n",
       " 'FreeParkingonPremises',\n",
       " 'IndoorFireplace',\n",
       " 'Petsliveonthisproperty',\n",
       " 'SafetyCard',\n",
       " 'Shampoo',\n",
       " 'SmokeDetector',\n",
       " 'TV',\n",
       " 'Washer',\n",
       " 'price_avg_2016',\n",
       " 'available_count_2016',\n",
       " 'available_count_2017',\n",
       " 'peak_available_count',\n",
       " 'review_count_2016',\n",
       " 'booked_nights',\n",
       " 'no_review',\n",
       " 'review_above_avg',\n",
       " 'review_above_75',\n",
       " 'review_above_90',\n",
       " 'rental_above_avg',\n",
       " 'rental_above_75',\n",
       " 'rental_above_90',\n",
       " 'avg_nights',\n",
       " 'churn',\n",
       " 'rental_category']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.head()\n",
    "list(listings.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listings_columns=[\n",
    " #'id',\n",
    " #'host_since_days',\n",
    " 'host_response_time',\n",
    " 'host_response_rate',\n",
    " 'host_acceptance_rate',\n",
    " 'host_is_superhost',\n",
    " 'host_has_profile_pic',\n",
    " 'host_identity_verified',\n",
    " 'neighbourhood',\n",
    " #'latitude',\n",
    " #'longitude',\n",
    " 'property_type',\n",
    " 'room_type',\n",
    " 'accommodates',\n",
    " 'bathrooms',\n",
    " 'bedrooms',\n",
    " 'beds',\n",
    " 'bed_type',\n",
    " #'price',\n",
    " 'security_deposit',\n",
    " 'cleaning_fee',\n",
    " 'guests_included',\n",
    " 'extra_people',\n",
    " 'minimum_nights',\n",
    " 'maximum_nights',\n",
    " #'calendar_updated',\n",
    " 'availability_30',\n",
    " 'availability_60',\n",
    " 'availability_90',\n",
    " 'availability_365',\n",
    " #'number_of_reviews',\n",
    " #'review_scores_rating',\n",
    " #'review_scores_accuracy',\n",
    " #'review_scores_cleanliness',\n",
    " #'review_scores_checkin',\n",
    " #'review_scores_communication',\n",
    " #'review_scores_location',\n",
    " 'review_scores_value',\n",
    " 'instant_bookable',\n",
    " 'cancellation_policy',\n",
    " 'require_guest_profile_picture',\n",
    " 'require_guest_phone_verification',\n",
    " #'reviews_per_month',\n",
    " 'AirConditioning',\n",
    " 'BuzzerWirelessIntercom',\n",
    " 'CableTV',\n",
    " 'CarbonMonoxideDetector',\n",
    " 'Dryer',\n",
    " 'ElevatorinBuilding',\n",
    " 'Essentials',\n",
    " 'FamilyKidFriendly',\n",
    " 'FireExtinguisher',\n",
    " 'FirstAidKit',\n",
    " 'FreeParkingonPremises',\n",
    " 'IndoorFireplace',\n",
    " 'Petsliveonthisproperty',\n",
    " 'SafetyCard',\n",
    " 'Shampoo',\n",
    " 'SmokeDetector',\n",
    " 'TV',\n",
    " 'Washer',\n",
    " 'price_avg_2016',\n",
    " 'available_count_2016',\n",
    " #'available_count_2017',\n",
    " 'peak_available_count'\n",
    " #'review_count_2016',\n",
    " #'booked_nights',\n",
    " #'no_review',\n",
    " #'review_above_avg',\n",
    " #'review_above_75',\n",
    " #'review_above_90',\n",
    " #'rental_above_avg',\n",
    " #'rental_above_75',\n",
    " #'rental_above_90',\n",
    " #'avg_nights',\n",
    " #'rental_category'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X= pd.DataFrame(listings, columns =listings_columns )\n",
    "X= pd.get_dummies(X)\n",
    "# list(X.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=listings['rental_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "names = [\"Perceptron\",\n",
    "         \"LogisticRegression\",\n",
    "         #\"Linear SVM\", \n",
    "         \"Decision Tree\", \n",
    "         \"Random Forest\", \n",
    "         \"AdaBoost\",\n",
    "         #\"RBF SVM\",          \n",
    "         \"Neural Net\", \n",
    "         \"Naive Bayes\",  \n",
    "         \"Nearest Neighbors\"] \n",
    "\n",
    "classifiers = [\n",
    "    Perceptron(),\n",
    "    LogisticRegression(),\n",
    "    #SVC(kernel=\"linear\", C=1, probability = True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=100, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    #SVC(gamma=2, C=1, probability = True),\n",
    "    MLPClassifier(hidden_layer_sizes=(100,50), max_iter=500, alpha=1), #increase number of iterations\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(5)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                            test_size=0.3, \n",
    "                            random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo: Perceptron           and Score: 0.1460\n",
      "Algo: LogisticRegression   and Score: 0.7608\n",
      "Algo: Decision Tree        and Score: 0.7997\n",
      "Algo: Random Forest        and Score: 0.7844\n",
      "Algo: AdaBoost             and Score: 0.7886\n",
      "Algo: Neural Net           and Score: 0.6314\n",
      "Algo: Naive Bayes          and Score: 0.7830\n",
      "Algo: Nearest Neighbors    and Score: 0.7469\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Algo: {0:<20s} and Score: {1:0.4f}\".format(name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo: Perceptron           and Score: 0.2139\n",
      "Algo: LogisticRegression   and Score: 0.7261\n",
      "Algo: Decision Tree        and Score: 0.5632\n",
      "Algo: Random Forest        and Score: 0.7498\n",
      "Algo: AdaBoost             and Score: 0.5389\n",
      "Algo: Neural Net           and Score: 0.6443\n",
      "Algo: Naive Bayes          and Score: 0.6971\n",
      "Algo: Nearest Neighbors    and Score: 0.7005\n"
     ]
    }
   ],
   "source": [
    "# Let's add cross-validation (k-fold cross validation)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for name, clf in zip(names, classifiers):    \n",
    "    scores = cross_val_score(clf, X, y, cv=10)\n",
    "    print(\"Algo: {0:<20s} and Score: {1:0.4f}\".format(name, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=99, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(min_samples_split=20, random_state=99)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "def visualize_tree(tree, feature_names):\n",
    "    \"\"\"Create tree png using graphviz.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    tree -- scikit-learn DecsisionTree.\n",
    "    feature_names -- list of feature names.\n",
    "    \"\"\"\n",
    "    with open(\"dt.dot\", 'w') as f:\n",
    "        export_graphviz(tree, out_file=f,\n",
    "                        feature_names=feature_names)\n",
    "\n",
    "    command = [\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"]\n",
    "    try:\n",
    "        subprocess.check_call(command)\n",
    "    except:\n",
    "        exit(\"Could not run dot, ie graphviz, to \"\n",
    "             \"produce visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "visualize_tree(dt, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo: Perceptron           and Score: 0.7274\n",
      "Algo: LogisticRegression   and Score: 0.7886\n",
      "Algo: Decision Tree        and Score: 0.7983\n",
      "Algo: Random Forest        and Score: 0.7844\n",
      "Algo: AdaBoost             and Score: 0.7886\n",
      "Algo: Neural Net           and Score: 0.7608\n",
      "Algo: Naive Bayes          and Score: 0.1224\n",
      "Algo: Nearest Neighbors    and Score: 0.7761\n"
     ]
    }
   ],
   "source": [
    "#7) Use pipeline to redo all your classifier but do StandardScale(), does it help?\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "    \n",
    "for name, clf in zip(names, classifiers):\n",
    "     pipe = Pipeline( [ ('scl', StandardScaler()),\n",
    "                    ('clf', clf)])\n",
    "     pipe.fit(X_train, y_train)\n",
    "     score = pipe.score(X_test, y_test)\n",
    "\n",
    "# #clf.fit(X_train, y_train)\n",
    "# #score = clf.score(X_test, y_test)\n",
    "     print(\"Algo: {0:<20s} and Score: {1:0.4f}\".format(name, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo: Perceptron           and Score: 0.7038\n",
      "Algo: LogisticRegression   and Score: 0.7761\n",
      "Algo: Decision Tree        and Score: 0.7024\n",
      "Algo: Random Forest        and Score: 0.7844\n",
      "Algo: AdaBoost             and Score: 0.7608\n",
      "Algo: Neural Net           and Score: 0.7497\n",
      "Algo: Naive Bayes          and Score: 0.6704\n",
      "Algo: Nearest Neighbors    and Score: 0.7803\n"
     ]
    }
   ],
   "source": [
    "# Add PCA after StandardScale() in the pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "    \n",
    "for name, clf in zip(names, classifiers):\n",
    "    pipe = Pipeline( [ ('scl', StandardScaler()),\n",
    "                   ('pca', PCA(n_components = 50)),\n",
    "                   ('clf', clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    score = pipe.score(X_test, y_test)\n",
    "    \n",
    "#        clf.fit(X_train, y_train)\n",
    "#        score = clf.score(X_test, y_test)\n",
    "    \n",
    "    print(\"Algo: {0:<20s} and Score: {1:0.4f}\".format(name, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2394, 92)\n",
      "\n",
      "EigenValues \n",
      "[  5.87929391e+00 +0.00000000e+00j   4.91708666e+00 +0.00000000e+00j\n",
      "   4.43405680e+00 +0.00000000e+00j   2.83526450e+00 +0.00000000e+00j\n",
      "   2.49777167e+00 +0.00000000e+00j   2.28776522e+00 +0.00000000e+00j\n",
      "   2.03932348e+00 +0.00000000e+00j   1.91248227e+00 +0.00000000e+00j\n",
      "   1.81217182e+00 +0.00000000e+00j   1.80458150e+00 +0.00000000e+00j\n",
      "   1.65365877e+00 +0.00000000e+00j   1.60690223e+00 +0.00000000e+00j\n",
      "   1.52811277e+00 +0.00000000e+00j   1.49829728e+00 +0.00000000e+00j\n",
      "   9.42894718e-02 +0.00000000e+00j   4.69032129e-02 +0.00000000e+00j\n",
      "   1.91172353e-02 +0.00000000e+00j   1.50916501e-01 +0.00000000e+00j\n",
      "   1.84886909e-01 +0.00000000e+00j   1.89489401e-01 +0.00000000e+00j\n",
      "   2.18604511e-01 +0.00000000e+00j   2.11565893e-01 +0.00000000e+00j\n",
      "   2.76270011e-03 +0.00000000e+00j   1.35436228e+00 +0.00000000e+00j\n",
      "   1.36110261e+00 +0.00000000e+00j   1.34745069e+00 +0.00000000e+00j\n",
      "   2.91041295e-01 +0.00000000e+00j   3.15176353e-01 +0.00000000e+00j\n",
      "   3.52422854e-01 +0.00000000e+00j   3.78032652e-01 +0.00000000e+00j\n",
      "   1.32098760e+00 +0.00000000e+00j   4.11222399e-01 +0.00000000e+00j\n",
      "   1.28754573e+00 +0.00000000e+00j   4.57160910e-01 +0.00000000e+00j\n",
      "   4.75215968e-01 +0.00000000e+00j   5.05482682e-01 +0.00000000e+00j\n",
      "   4.89435394e-01 +0.00000000e+00j   4.85742520e-01 +0.00000000e+00j\n",
      "   1.23285629e+00 +0.00000000e+00j   5.27275460e-01 +0.00000000e+00j\n",
      "   5.48027651e-01 +0.00000000e+00j   1.20032631e+00 +0.00000000e+00j\n",
      "   5.65346802e-01 +0.00000000e+00j   6.07210768e-01 +0.00000000e+00j\n",
      "   6.16037020e-01 +0.00000000e+00j   1.18858487e+00 +0.00000000e+00j\n",
      "   6.28662977e-01 +0.00000000e+00j   1.17298196e+00 +0.00000000e+00j\n",
      "   1.15573635e+00 +0.00000000e+00j   6.62965678e-01 +0.00000000e+00j\n",
      "   6.70191227e-01 +0.00000000e+00j   6.84510763e-01 +0.00000000e+00j\n",
      "   7.00650348e-01 +0.00000000e+00j   7.11391943e-01 +0.00000000e+00j\n",
      "   1.13031531e+00 +0.00000000e+00j   1.12744747e+00 +0.00000000e+00j\n",
      "   7.33582464e-01 +0.00000000e+00j   7.48350198e-01 +0.00000000e+00j\n",
      "   7.95980107e-01 +0.00000000e+00j   7.67806035e-01 +0.00000000e+00j\n",
      "   7.57171804e-01 +0.00000000e+00j   8.05990098e-01 +0.00000000e+00j\n",
      "   1.11269232e+00 +0.00000000e+00j   8.18402674e-01 +0.00000000e+00j\n",
      "   8.48544388e-01 +0.00000000e+00j   1.09732999e+00 +0.00000000e+00j\n",
      "   8.66012439e-01 +0.00000000e+00j   1.08157671e+00 +0.00000000e+00j\n",
      "   1.07717018e+00 +0.00000000e+00j   8.89397291e-01 +0.00000000e+00j\n",
      "   9.03977345e-01 +0.00000000e+00j   1.06664248e+00 +0.00000000e+00j\n",
      "   9.23048292e-01 +0.00000000e+00j   1.05652845e+00 +0.00000000e+00j\n",
      "   1.03739149e+00 +0.00000000e+00j   1.01292006e+00 +0.00000000e+00j\n",
      "   1.02201890e+00 +0.00000000e+00j   9.54051448e-01 +0.00000000e+00j\n",
      "   1.04847379e+00 +0.00000000e+00j   9.30372652e-01 +0.00000000e+00j\n",
      "   1.04329761e+00 +0.00000000e+00j   9.92589880e-01 +0.00000000e+00j\n",
      "   9.74481410e-01 +0.00000000e+00j   9.63405654e-01 +0.00000000e+00j\n",
      "   9.32300596e-01 +0.00000000e+00j   9.88732862e-01 +0.00000000e+00j\n",
      "   2.87504402e-15 +0.00000000e+00j  -1.34626987e-15 +0.00000000e+00j\n",
      "  -1.11564908e-15 +0.00000000e+00j  -2.25105173e-16 +1.13489985e-17j\n",
      "  -2.25105173e-16 -1.13489985e-17j   2.22612474e-16 +0.00000000e+00j]\n"
     ]
    }
   ],
   "source": [
    "##Finding the best number of PCA components\n",
    "\n",
    "# scale X's\n",
    "sc = StandardScaler() # x(i)_new = (x(i) - mean(x))/std(x)\n",
    "#sc = MinMaxScaler()   # x(i)_new = (x(i) - min(x))/(max(x)-min(x))\n",
    "\n",
    "sc.fit(X)\n",
    "X_std = sc.transform(X)\n",
    "print(X_std.shape)\n",
    "#print(X_std.std(axis=0)\n",
    "#print(X_std.mean(axis=0))\n",
    "\n",
    "cov_mat = np.cov(X_std.T) # careful here need to transpose \"X\" \n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "print('\\nEigenValues \\n%s' % eigen_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangweny/anaconda/lib/python3.6/site-packages/matplotlib/patches.py:692: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  self._height = float(height)\n",
      "/Users/yangweny/anaconda/lib/python3.6/site-packages/numpy/core/numeric.py:531: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4FfX1x/E3ENaEJUBAwUqwwtGigiDKJuKGRUXBWq1r\nRQUVadG61qq4IEVFEeuGihuuuP5wxboraltEqVo4iihuiCyRgISw/v6Ym3ATkpubmElu7nxez8PD\n3ebOyZcwZ77LnKm3ZcsWREQkeurXdgAiIlI7lABERCJKCUBEJKKUAEREIkoJQEQkojJqO4BkLVu2\nutLLlbKzm5GXtzaMcOoctUVA7RBQO2yV7m2Rk9O8XnnvpXUPICOjQW2HkDLUFgG1Q0DtsFWU2yKt\nE4CIiJRPCUBEJKKUAEREIkoJQEQkopQAREQiSglARCSiQk0AZraPmb1RxutDzew/ZvaemY0MMwYR\nESlbaAnAzC4E7gaalHq9ITAZGAzsB4wys/ZhxSEiImUL80rgL4CjgOmlXt8VWOjueQBm9g4wEHg8\nxFhCs2jRF9x++82sW7eOgoIC+vbtz6mnjqJevXIvvquSa665ggMPHEyfPv3KfP+LLxayenU+PXr0\nZNy4v3LppVfRsGHDSu9n7tw5XH75X8nN7Vz8WqtW2Ywff22lvuP//u9Jrrzy72W+//7777J06Q8c\neeRRlY6vyLhxf+XII39Hz557AbB27c8ce+xwHnvsGZo1a1b8uREjjueqqybyq1/tWOF3XnLJBUyY\ncH2VY5K66Z5nP+Wtud/Wdhjl6r1LO445YOdQvju0BODuT5pZbhlvtQBWxT1fDbSs6Puys5tV6Yq9\nnJzmld4mWfn5+Ywffxn/+Mc/yM3NZdOmTYwdO5ZXX32e4447rlr31aRJQ1q2bFruz/Poo+/Qtm1b\ncnL247bbbinzM8m0RatWzejXry+TJ0+ucqytWjWjceOG5e5v6NBDqvzdRRo3bkirVs3i9tGcAw88\ngA8+mM1RRwWJ5ZNPPqF162x69uxWYtvy4rrrrjt+cVx1SZj/N1LRPc9+yux5323z+o95BQC0y25a\n0yElpWmzRqH9W9VGLaB8IP6naQ78VNFGFdXqmPHaQv6z4McSrzVoUI9Nm6p+x7OKMu+LLz7PHnv0\nJDOzDcuWrQbgggsuo2HDhsya9XqJs+AjjjiEmTNncc01V5CRkcEPPyxhw4YNHHjgYGbPfoulS39g\n4sQbWbr0hzK3W7duA6tWFfDVV0uYOHE8a9asZvnyZRx11DEMGDCQJ554koyMhnTokMvll/+VBx54\nlBEjTuC++x6hadOmzJw5g4KCDQwadCDXXTeBwsJ1NG7chAsvvIT27bcr/pl++mkthYUbin+eIhs3\nbmTMmFGMGDGSLl268uc/n8UNN9zM1VdfTqdOuSxe/BUAV145ocR3PPnkY7z55usUFBTQqlUrJkyY\nxD//+RKLF3/FsGG/44or/ka7du357rtv+c1vunH++X9lzZo1TJx4FatWBecJ55xzAb/+9c48+eQM\nnnvuGdq0aUteXh4//bS2RJwHH3w4U6fewr77HgzAgw8+ypAhR5SIY+PG9WRmNi+O4/nnZ7J582ZO\nO+0MrrrqMmbOnMWHH37AvffexebNmykoKGDcuPE0bNiwzFjz8vK45ppxrFmzhi1btnDppVeSnd26\nzPhTSU5O823+jdNBWceBIivy1wHQpkWJUWnaZTelZ5ec0M6yq8Mv+bdKlDxqIwHMB7qYWWtgDcHw\nz6RaiOMXW758GR06dCzxWvzwQ3m22257LrroUq6/fgJLlnzHpEk3M23aVGbPfoudd+6acNtvv/2W\ngw4azH77HcDy5csYM2YUw4cfzZAhh9OmTRt+85vdAGjQIIP99juAN954lSFDDue5557j+utv5oYb\nruXoo4+lb9/+zJnzb+644xbGjRtfYh8ffDCHMWNGFT/v128Axx9/MuPGjefCC8+hTZu2nH322OLE\nsdtue3DBBZfw1FOPM336vQwcuD8AmzdvZtWqVdx0023Ur1+fv/xlDPPnf1piX9988zWTJ99C48ZN\nOOaYI1mxYjmPPfYwvXrtzfDhR/PNN18zYcKVXHPNdTz++KM88MCj1K9fn9NOO3GbtunWbTfy8/NZ\nuvQHsrNbM2fOv/jzn/9SIo727Vty0kl/LI6jefPmTJx4Y4nv+fLLRVx++dW0bZvDAw/cw+uvv8Lg\nwUPKjHX69PsYMGAgw4Ydzccfz2P+/E9ZuPDzbeK//fZpFf5eSNXEH/TLO8gXvVbWSV26JsNk1FgC\nMLPjgSx3v9PM/gLMIpiEvsfdt+2XVdIxB+xc4/+w7dtvz2efLSjx2vfff8ePPy7d5rPx917u2nUX\nALKymtOpUy4QHIgKC9cn3A6gdevWzJjxMG+++TrNmmWycePGcuMbOnQYkyZNpFOnXDp37kzLlq1Y\ntGgh06ffy0MP3Q8EiaK0Xr32KnP8fvvtO7DHHj345JOPS8xF9OrVG4Ddd9+Dd955s/j1+vXrF585\nN23alB9//HGbeDt23IFmzTIBaNOmLevXr2fRooXMnTuHV199GYDVq/P57rtv6dx5Jxo1agTArruW\nHNYpcvjhR/Dyyy+y/fYdGDBgv+J5kKI4srNblIhjxx07bfMdOTk53HTT9TRt2oxly35k9927lxvr\n118v5rDDjoj9/N3ZfffuvPzyi9vEL79Msmf25R3kpWyhJgB3/wroE3v8cNzrzwLPhrnvmtC//wCm\nT7+H4cOPpmPHHdi4cSP/+Mdkevfeh65dd2HFihUA/PDDEvLzt057JJogbtSocbnbATz66IPsttse\nDB9+NHPnzuG9994BgoPt5s0lk0Uw8bmFhx+ezimnnATAjjvmctxxJ7L77t1ZvPgrPvzwg6R/3k8+\n+ZhFi76gR489eeSRBzn++OA73efTrl17/vvfeXTuvFPx5xcu/Jy33nqDu+66n3Xr1pV51l5WW3Tq\nlMvgwb9h8ODfkpe3kmeffYYddtiRL79cRGHhOjIyGvLZZ87gwUO22Xbw4EM577wxtG7dhjFjzt0m\njqysDI48cljc/rddCHfttdcwY8YzNGuWyfjx4xLGmpuby4IF/6NLl6589NFc3n33nTLjl8r7pWf2\nUrE6cz+AVJSZmcXf/nYl1147ns2bN7N27Vr699+X4cOPZtOmTWRlZTFy5B/Jze3M9tt3rPgLgV12\n2TXhdv37D2Ty5Ot49dWXycrKokGDBqxfvx6zXbnttiklVu8AHHbYkUybdgd9+vRh+fI1nH32WG64\nYSLr16+nsHAdY8eev00MpYeAACZOvJGJE69mwoTrad9+O0aNOoWePXsB8MILz/HYYw/TpEkTLrvs\nKr74YiEAO+zwK5o2bcpZZ50KBGfNy5cvq7ANTj75VCZOvJqZM59i7dqfOfXUUWRnZ3PiiX/kzDNP\npVWrbJo2LXvCrkWLFuy4Yy4rV64oXvkTH0dGRoMK4zjkkCGMHj2Spk2bkJ3dJuFnTzrpVP7+96uY\nNesF6tWrx8UXX0ZWVtY28Utyyjvo6yAfjnqlhxhSVVVuCBPlsb3SwmqLMWNGccEFlxQPZaU6/U4E\nUqUdSg/tlD7Tr4mDfqq0RVgS3RBGPQARqVGJhnZ0pl+zlADkF7nlljtrOwSpAzS0k5qUAESk2iUa\n2tFBP3UoAYhItfvPgh/JW11IdvPGgIZ2UpUSgIhUi/iz/qKD//Wjy65dJakhrRLAM28vKvE8M7Mx\nP/9cWOXvG7bvThV/SCTCyhvbz27emN67tKvN0CQJuiHML7BkyfeMGnVK0p8fNeoUliz5nhdeeLbE\nFbPxPv/cuffeu7Z5fdy4vzJ37pxqiW/QoD6MGTOqxJ9ly8q+yrI8RxxRfkG3FSuWM2nSxEp9X2nP\nPPME06ZNLfHamDGj+OCD/5R47aabJiV9odWUKTfw/fff/6K4om7Gawu54LZ3i/+89O+vSxz4f7v3\njlw/uh/Xj+6n4Z46IK16AHXFoYcOLfe9Ll2MLl0s1P23aNEy1NU7bdq05fzzL6727x06dBgvvfR8\ncemJDRs2MHv225xxxtlJbT927Hlpv+Y7DFq2mb6UAKrJmDGj6NLFWLToC9auXcPVV1/Ldtttz9Sp\nt/Kvf71H+/btWbUqKHo6bdpU2rRpwzfffM3OO3dlyJDDWbFiORdccA5jxpxTXA20dPVLgBdeeJbF\ni7/irLP+RGFhISeccDRPPPFsuRUsK+PWW6fQoEEDRo0azbnnns2xx57A/Pmf8vXXX5GXl8fq1fmc\nc86FdO/eo3ib8vY7btwl3Hnnffzxj3+gR4+exVcHT5x4I1lZWdxxxy3Mm/chmzdv5thjT+CAAw5i\n3ryPmDJlEs2bt6BBgwZ067ZbifgGDTqQqVNvZd26dTRp0oS3336Tvffeh6ZNm5Ybx0UXnUuLFi3p\n27c/7703mwkTxrNu3RYmTZrI+vWFrFixnJEjRzNw4KAyY83MzGTy5OuYP/9TNmzYyGmnjWLffQeV\nGX+6ip/Q1QE/vSgBVKNdd+3G2LHnMXXqrfzzn7Po3Xtv5s37kLvvfoCCgrX84Q8lb4By+OHDmDz5\nOoYMOZxZs17gsMO29gxWrlxRYfXLeOVVsCxLfv6qEqUecnLaMW7ceM4442xGjz6da64Zx667dqNf\nvwHMn/8pjRs34eab72DRoi+48spLuf/+R5Le788//8xBBx3CuedeyJVXXsr7788mMzOLJUu+4/bb\np1FYWMgZZ4ygd+99uOGGvzN+/HXsuGMnJk3athhd48aNGThwEG+99TqDBw/hhRdmMmrU6IRxrFy5\ngmnTHqRhw4a8995sABYv/oo//OEEevbci48/nse0aVMZOHBQmbE2bNiIVat+4q67HiA/P5/HHnuI\njIyGZcbfvHn61NfXhG40KAFUo65dg6Gb9u3bs2LFCr7++mt22WVX6tevT2ZmFjvtVPKsqXPnndi0\naRM//LCEV1/9JzfddBuff+4ASVa/3Fodo7wKlmUpbwgoIyODY445jvHjx/HUU88Xv1405LLTTr9m\n5coVJbZJZr9F7dKuXXvWr1/P0qULcV9QnIQ2btzIDz98z8qVK4urc+6+e3e+/fabbb5r6NDh3Hrr\nFPbcsxerV68urqxaXhzbb99hm55QmzZtuf/+aTz//P8B9UpUKC0d65IlS+jWbY9Yu7Vg5MizeOih\n+8uMv3nzcIfuwpRo3b4mdNOXEkA1Kl0tsnPnzjz99Aw2b95MYWEhX321aJttDj/8SG677WZyczuX\nOIMsr/plo0aNWLFiOQDuW0tRl1fBsjLy8/OZPv1e/vSnc7n22vFce+3k2H7mc8ghh7Jo0UJycnJK\nbJPcfku2S6dOuey5515cdNHf2Lx5M/fddzcdO+5ATk4OX331Jbm5nZk//39lnlH/+tc7U1DwM48/\n/mhxGeZEcZRV7fPuu+9g6NBh9O3bn+efn8mLLz5Xbqy5ubm8/vqrAKxZs4bLL7+Yo476fZnx1zUa\n25e0SgCll23W9oRfly7GPvv04/TTT6Zt2xyys1tv85n99z+IKVMmbXNTkvKqX+6zTz+eeeZJzjrr\nNMx2JTMzqE9fmQqWpYeAAM48cwwPPzyd448/mUMOOZQFC+bz+OOPAvDZZ87YsWdRUFDAhRdeWmK7\nyuy3SP/+A/nwww8YPfp0CgrWMnDg/jRrlskFF1zC+PHjyMzMpFmzZuUOqRx22BHceuvNPPnk1gN3\nZeLYf/8DufXWKTz44H3k5LTjp5/KvyHdgAH7MWfOvznrrNPYtGkTI0aMpE+ffmXGX9dobF9UDTQi\nqtoWRRPWw4YdHUJUNS/qvxNFZ/0NGtRj+U/rNLZP+v9OqBqoSESVN7bfLrupxvZFCUASO+20M2o7\nBPkFyqvJc/axe6b1Wa8kRwlAJM1oCackS6UgRNJM0Vk/oGEeSUg9AJE0oLN+qQolAJE6SBduSXVQ\nAhCpg3TDFakOSgAidYSGeaS6KQGIpDDdcEXCpAQgksJUrkHCpAQgkmI01CM1RdcBiKQYreOXmqIe\ngEgtK72kU2f9UlPUAxCpZfFn/KCzfqk56gGI1AKN80sqUAIQqSFa0impRglApIZoSaekmqQSgJnt\nBgyKff4Nd/8oiW3qA7cB3YFC4HR3Xxj3/gnAecAm4B53v73S0YukME3uSqqrcBLYzE4C/g/YCegE\nPG1mpybx3cOAJu7eF7gYuKHU+5OAg4D+wHlmll2ZwEVSnSZ3JdUl0wM4D9jb3VcAmNk1wBvAPRVs\nNwB4CcDd3zezvUq9/1+gJbARqAfUjZsTiySgyV2pS5JJAA2KDv4A7r7czDYnsV0LYFXc801mluHu\nG2PPPwE+AH4GnnL3nxJ9WXZ2MzIyGiSx25JycppXept0pbYIhNkOcz9fRt6aQtq2bELbVk3o371j\nyrZ7qsZVG6LaFskkgHlmdhMwLfb8NGBeEtvlA/GtWr/o4G9mewCHAZ2BNcCDZvZ7d3+8vC/Ly1ub\nxC5LyslprvuexqgtAmG0Q1ln/RPP6Fv8fiq2u34ftkr3tkiU3JK5EGwksJ5gyOc+YAMwOontZgOH\nAphZH+DjuPdWAQVAgbtvAn4ENAcgdZJKN0hdVWEPwN0LgAur8N1PAweb2bsEY/wjzOx4IMvd7zSz\nqcA7ZrYe+IIguYikPK3ukXRRbgIws7nu3jM23h8/QVsP2OLuCQfk3X0zcGaplxfEvX8HcEflQxap\nXaXvxqWzfqmryk0A7t4z9vc2w0Rm1jjMoERSjVb3SDpK5jqA90o9rw/MCS0ikRSkcX5JR4mGgF4j\nuPqXUss+NwIzww1LpPbprF/SXaIhoAMAzGyKu4+tuZBEUkP8WL/O+iUdJXMdwEVmNhzIIpgAbgB0\ndvfLQ41MpIZpdY9ETTIJ4EmgGbAz8DYwEHgv4RYidZBW90jUJJMADOgCTCG4GOx84IkwgxKpKRrn\nlyhL5krgpe6+hWAN/x7u/j2gZaCSFrS6R6IsmR7Ap2b2D+B24CEz6wA0DDcskZqjs36JqmQSwFlA\nP3f/n5mNAw4Ejgs3LJHwlDXsIxJFCYeAzMyA9u7+NoC7zwQmAFoWKnWWhn1EAokuBLuCYMIXMxsG\nvB57fgnwfk0EJ1Id4s/4GzSop8lekZhEQ0AnE6z+6QBcBVwEbAcc4+6zaiA2kWqh5Z0iZUuUAFa7\n+xJgiZntDTwA/DZWv18kpZW3vDPdb/4hUhmJEkB8/Z/l7n5e2MGIVBeVcRCpWKIEEH8PgIKwAxH5\npXRRl0jlJEoA3cxsUexxx7jHRTeE2Snc0EQqR2f9IpWTKAF0rbEoRKpAxdtEfplE5aAX12QgIpWl\n1T0iv0wyVwKLpCyd8YtUnRKA1Ckq4yBSfZJKAGbWH9gduBfYx93fCjUqkXJoolek+lSYAMxsLDAM\n6Ag8Dkw1s2nuPins4ERAyztFwpLM/QBOAQ4Bfnb3FUBv4NQwgxKJp+JtIuFIZghok7uvDwqDArAO\nUDkICZXO+kXCl0wP4E0zmwRkxqqCzgReDTcsiTqd9YuEL5kewAXASGAeQYXQ54GpYQYlAlriKRK2\nZBJAMyDD3X9vZh2BM4BGwMZQI5NIKe+qXhEJTzJDQA8D28cer45tMz20iCSS4od8QMM+IjUhmR5A\nJ3c/AsDd84FLzeyjcMOSKNBEr0jtSqYHsMXMdi96Yma7ABvCC0miQhO9IrUrmR7A+cA/zexbglLQ\nbYGTQo1K0pbO+kVSR4UJwN1fMbMdCUpBbAhe8sIKNhMpk0o5iKSOZEpBdALGAK0JegCYGe6uq4Gl\nSnTWL5IakhkCmgG8HfuzpYLPFjOz+sBtQHegEDjd3RfGvd8buJEgqfwAnOju65IPXeoCLe8USV3J\nJICG7n5+Fb57GNDE3fuaWR/gBuBIADOrB9wFHO3uC83sdKAT4FXYj6Qw3bRFJHUlkwDeMbOhwCx3\nX1+J7x4AvATg7u+b2V5x73UFVgDnmtluwPPuroN/mtBEr0jdkEwCOJpgDoC4gnBb3L1BBdu1AFbF\nPd9kZhnuvpFgJVG/2PcuBJ4zsznu/lp5X5ad3YyMjIp2ua2cnOaV3iZd1VRbzP18GXlrCmnbsglt\nWzWhf/eOKfXvkEqx1Ca1w1ZRbYtkVgF1qOJ35wPxrVo/dvCH4Ox/obvPBzCzl4C9gHITQF7e2koH\nkJPTnGXLVld6u3RUk22xadMWsrMaM/GMvsWvpcq/g34nAmqHrdK9LRIlt2RWAbUDTgCyCCZsGwCd\n3f3kCjadDQwFZsTmAD6Oe28RkGVmO8cmhvcFplUUi6Qu3apRpO5J5krgp4AewIlAJnAEsDmJ7Z4G\n1pnZu8BkgvH+481sVGwu4TTgYTP7D/CNuz9fpZ9AUoKu6hWpe5KZA2jr7gNi9wR4CpgAvFLRRu6+\nGTiz1MsL4t5/Ddi7ErFKCilveacme0XqjmR6AHmxvx3o7u6rgIbhhSR1gap3itR9yfQAXjOzxwlq\nAr1sZj0JbgspEaczfpG6LZlVQH8zs1+7+2IzOw7YD7gy/NAk1WiiVyS9lDsEZGaHx/4+Gegf+3s3\ngiWcB9dMeJJKNNErkl4S9QB6A88B+5fx3hbggVAikpSiq3pF0le5CcDdx8Uefuful9ZQPJJiVL5Z\nJH0lMwk81Mwuc/ekK4FKetFZv0h6SiYBrAAWmNlcoKDoRd0PID2pfLNIdCSTAO4PPQpJGSrfLBId\nySwDvd/MWhOUgSiuBRR2YFJzNNErEk0VXglsZhOALwmuBH6HoHzz30OOS2qQlneKRFMyQ0DHAb8C\npgDjgR2B88IMSmqezvpFoieZBLDE3fPN7BOCWkBPmdl1YQcm4dJVvSKSTDG4VWZ2EvABcEKstn92\nuGFJ2DTsIyLJ9ABOA45z9+mxewNPBXRhWBrQsI9ItJWbAMxsDPCQu38P3ADg7hr7r6PuefZT3pr7\nbfFzDfuISKIhoJ4EF4A9YmYq/lbHzZ73ner3i0gJiWoBnWpmTYFhwF/M7HbgQeBed19cUwFK1ZWY\n6F2j9f0iUlLCSWB3L3D3R9x9CNAfWEVwH9+XaiQ6+UXiJ3rbtmyiM34RKSGZSeAiTYCmQGMgP5xw\npLoVnfXn5DRn2bLVtR2OiKSQhAnAzNoCxwInAG0I6gINc/dvE20ntUfr+0UkWYlWAb0E7AM8DVzs\n7m/VWFRSZarfLyLJStQDmAEc7e5raioYqR6a7BWRZCRaBXRPTQYiVaP6/SJSVcmUgpAUFr/SB7S+\nX0SSV5lVQJKiNOQjIlWRaBL4XqDc+wDrlpC1Ryt9RKQ6JBoCegN4E2gOdABeA14mqASqoaNapEqe\nIlIdEk0C3w9gZqOBvu6+OfZ8BvB+zYQn5dGwj4j8UsnMAbQEWgPLY8/bA1mhRSRl0rCPiFS3ZBLA\nNcB/zWw2wQ3h9wH+FGpUsg1d4CUi1a3CBBC7EcwrQD+CSeEz3f3HCjaTEGjYR0SqU4UJwMwaASOA\nXQjO/Mea2UR3Xx92cFGnYR8RCVMyQ0C3AssIbhCzAdgZmAaclGgjM6sP3AZ0BwqB0919YRmfuxNY\n6e4XVy709KdhHxEJUzIJoJe79zSzIe6+1sz+CHycxHbDgCbu3jd2I/kbgCPjP2BmZwC7Eyw3lTJo\n2EdEwpJMAtgSGwYquiisLQkuEIszAHgJwN3fN7O94t80s34EE8pTCYaXIk91fUSkJiWTAG4CXgG2\nM7ObgOHAlUls14LgDmJFNplZhrtvNLPtgXGx7zommUCzs5uRkdEgmY+WkJPTvNLb1Ja5ny8jb00h\nbVs2AaBtqyb0796x2n6GutQWYVI7BNQOW0W1LZJdBfQBsD/BMtCh7v7fJL47n+Aq4iL13X1j7PHv\nCXoSLwDbAc3MbIG731fel+XlrU1ilyXVtbtgbdq0heysxkw8o2+J16vjZ6hrbREWtUNA7bBVurdF\nouRWYUkHM8sAOhMc0H8CepjZyUnsdzZwaOw7+hA3b+DuN7t7L3cfBEwEHk508BcRkeqXzBDQw0An\nYD5bx/63AA9UsN3TwMFm9i5QDxhhZscDWe5+ZxXjTTta6ikitSWZBLAHsKu7JzPxWyxWO+jMUi8v\nKONz91Xme9ONlnqKSG1JJgHMJxinXxJyLJGlpZ4iUhuSSQDNADezT4B1RS+6+wGhRZXmNOwjIqkg\nmQQwIfQoIkbDPiKSChLdEaynu88luYu+pJI07CMitS1RD+BMYBRlX/S1BdAQkIhIHZbojmCjYn/v\nX3PhpCeVeBCRVJRMOegBwAUEdwGrR3A1cCd3zw03tPQRP+YPuo+viKSGZCaB7wauBU4BbgaGAHND\njCktacxfRFJNMgmgwN3vNbNcIA8YCXwQalRpQEs9RSTVVVgLCFhnZq0BB/rErgjODDesuq9o2Ac0\n5CMiqSmZHsCNwGPAUcB/zOwE1ANIioZ9RCSVVdgDcPfHgcHuvhroBZwInBB2YCIiEq5EF4LdS9xF\nYGZW+iOnhhRTnaVxfxGpSxINAb1RU0GkC5V4EJG6JNGFYPcXPTazHgRX/m4EXnb3bco6S0Dj/iJS\nVyRzR7DzgMeBDgR3BnvWzEaEHZiIiIQrmVVAZwC93D0fwMyuIrjd471hBlYXqMSDiNRlyVwHsBLY\nEPd8DZC+d1CuhPi1/qD1/iJStyTTA/gCeM/MHiGYAxgO5JvZ5QDuflWI8aU8jfmLSF2VTAL4LPan\nSez5P2N/1wslIhERqRHJJICn3f2/8S+Y2dHu/kRIMYmISA1IJgHMNLNb3f36WE2g24EuQCQTgC72\nEpF0kcwkcE+gu5m9C/wb+BfQO9SoUpiKvIlIukimB1CPYBVQs9jjzbE/kaWJXxFJB8n0AD4FvgL2\nAvYB+hL0BEREpA5LpgcwxN0/jD1eDhxrZr8PMaaUo3F/EUlH5fYAzOwsAHf/0My6lXq7f6hRpRiN\n+4tIOkrUAxhJsOIHYDrBZHCRgaFFlKI07i8i6SbRHEC9ch6X9VxEROqYZCaBIe7GMOU8FxGROibR\nEFBkD/Kq8ikiUZAoAXQzs0Wxxx3jHtcDtg83rNoVf2cv0MSviKSnRAmga41FkYI06Ssi6S7RLSEX\n12QgIiJo5p9zAAAKtElEQVRSs5K5EKxKzKw+cBvQHSgETnf3hXHvHwecQ3CPgY+B0e4e6RITIiI1\nKdlVQFUxDGji7n2Bi4Ebit4ws6bAeGB/d+8PtAQODzEWEREpJbQeADAAeAnA3d83s73i3isE+rn7\n2rg41iX6suzsZmRkNKh0EDk5zZP63D3Pfsrsed8BkLemkLYtmyS9bV2Rbj9PVakdAmqHraLaFmEm\ngBbAqrjnm8wsw903xoZ6lgKY2Z+ALLbeaaxMeXlrE71dppyc5ixbltzti9+a+23xyp/srMb07JKT\n9LZ1QWXaIp2pHQJqh63SvS0SJbcwE0A+EL/n+u6+sehJbI7gOoLVRr9z91q/7kArf0QkSsKcA5gN\nHApgZn0IJnrjTSW4z/CwuKEgERGpIWH2AJ4GDo7dSaweMMLMjicY7pkDnAa8DbxmZgBT3P3pEOMR\nEZE4oSWA2Dj/maVeXhD3OMzeh4iIVCDMHkDK041eRCTKIn0Wrhu9iEiURboHAFr5IyLRFekegIhI\nlCkBiIhElBKAiEhEKQGIiESUEoCISEQpAYiIRJQSgIhIREXqOoD4K39BV/+KSLRFqgcQf+Uv6Opf\nEYm2SPUAQFf+iogUiVQPQEREtlICEBGJKCUAEZGIUgIQEYkoJQARkYhSAhARiSglABGRiFICEBGJ\nKCUAEZGIikwCmPHaQlbkr6vtMEREUkYkEsAzby/i829/omnjBqr9IyISE5laQN06t6Zb59YM23en\n2g5FRCQlRKIHUNozby/imbcX1XYYIiK1KjI9gPLEJwL1DkQkSiLZAxARESUAEZHIivwQUDwNB4lI\nlKgHkIAmi0UknakHkKTyEsGwfXcqfk+9BhGpS5QAqlmyiUIJRURqW2gJwMzqA7cB3YFC4HR3Xxj3\n/lDgcmAjcI+73xVWLHVZZRNKecklM7MxB/fsWKUkVFc+p4QpUjlh9gCGAU3cva+Z9QFuAI4EMLOG\nwGSgN/AzMNvMZrr70hDjkQioKGmUToTlfa7041T/XGW3ycxszM8/F1ZLDFJ3hZkABgAvAbj7+2a2\nV9x7uwIL3T0PwMzeAQYCj4cYj4iEoKaSX1jfXVHvOJ2TXL0tW7aE8sVmdjfwpLu/GHv+NbCTu280\nswHAn9z92Nh7VwFfu/vdoQQjIiLbCHMZaD7QPH5f7r6xnPeaAz+FGIuIiJQSZgKYDRwKEJsD+Dju\nvflAFzNrbWaNCIZ/3gsxFhERKSXMIaCiVUB7APWAEUBPIMvd74xbBVSfYBXQraEEIiIiZQotAYiI\nSGpTKQgRkYhSAhARiSglABGRiErLWkAVlaFIZ7GrrO8BcoHGwHjgf8B9wBbgE+Bsd99cSyHWODNr\nB3wAHExQeuQ+ItYWZvZX4AigEcH/jTeJWDvE/m/cT/B/YxMwkoj+PhRJ1x5AcRkK4GKCMhRRcSKw\nwt33BX4L3ALcCFwae60esZIcURD7Tz8VKIi9FLm2MLNBQD+gP7Af8Csi2A4Ey9Iz3L0fcBVwDdFs\nh2LpmgBKlKEA9kr88bTyOHBZ7HE9gjOcXgRnfAAvAgfVQly1ZRJwB/B97HkU2+IQgutwngaeBZ4j\nmu3wGZARGyFoAWwgmu1QLF0TQAtgVdzzTWaWlsNdpbn7GndfbWbNgSeAS4F67l603nc10LLWAqxB\nZnYKsMzdZ8W9HMW2aEtwEvR74EzgIYIr86PWDmsIhn8WAHcBNxPN34di6ZoAEpWhSHtm9ivgdWC6\nuz8MxI9pRqnsxqnAwWb2BtADeABoF/d+VNpiBTDL3de7uwPrKHmgi0o7nEvQDl0J5gfvJ5gTKRKV\ndiiWrgkgURmKtGZm7YGXgYvc/Z7Yyx/GxoEBhgBv10ZsNc3dB7r7fu4+CPgIOBl4MYJt8Q7wWzOr\nZ2YdgEzg1Qi2Qx5bRwZWAg2J6P+NIml5JXBZZSjcfUHtRlUzzGwKcCxBN7fIWILubiOCOkwj3X1T\nLYRXa2K9gDMJekN3EbG2MLPrgP0JTvouAb4kYu1gZlkEK+S2J/i5pwBziFg7xEvLBCAiIhVL1yEg\nERGpgBKAiEhEKQGIiESUEoCISEQpAYiIRFQkro6V1GFmuQSX5P+PoABXI4IyDSPc/dtSn+0A3O3u\nh1ZhPx+5e48qbDcIuCJ27UDp9w4jWEKZBTQgKK0wri4XDzOzUcBqd3+ktmORmqcegNSG7929h7vv\n6e7dCNZi/6P0h9z9+6oc/GPbVvrgn4iZFRXWG+Hu3YHeBFeTXlmd+6kF/QiqxkoEqQcgqeAtglLF\nmNlXwL8ISjecBMxw91wzu4/gKs5ewA7Ale5+r5m1BqYBuxCU/v6Lu79mZlvcvZ6ZXQF0BX4NtAGm\nuvv1ZtYitt0OQIdYDCcniPFvsX1+BuDuBWY2OrZfzKwrcCfQGvgZ+LO7/ycW988EBQpbAefEfq7u\nwDPufl6sZtFRsW3bExRsO8/dt5jZJQQVXjcRXOF9IUE1z6cJyhfvCSwFfu/uK2OJ6iqCq1y/JLiw\naUWsXacTFIbLjP2s2bF2P8DMlsTa58LYvr4ETnT3dQnaROo49QCkVsXKNR9LUL6jyIvubsCPpT7+\nK2BfYChBlU+Aq4GF7r4rwYH1mjJ2sxtwIEHyOMPMegKHAR/FSoZ3AfoCPROEuidBYirm7t+6+yux\npw8CN7v7HgQ1Z54ws6Iz6w6xXsPlwL0EVyT3AEaaWVFNnt7A74BuQB9guJkdSnCA7hXb/86xbSFI\nIDe6+24E9WtOMLMcYCJwiLvvCcwCro0LeYW7701QHfWSWOwzgctjBfPGA4PdvRfBleS7JGgPSQPq\nAUht6GBmH8UeNwb+TXDfhiL/2nYTAF6OnRV/QnC2DEF9++MB3P1jggN5aY+4+xoAM5sJHODuk8xs\nbzM7B9iV4Ow3K0HMmwnKimwjVmJgZ3d/KhbH+2a2ErDYR16M/b0Y+MTdf4xtt5LgLBxgprsvjb3+\nKHAAQdG2R9y9IPb6PcAfgeeBH939w9i2Re2xD7Aj8LqZQTBPsTIu1JfiPn9UGT/Ks8BsM3sGeNLd\nPyrjM5JGlACkNnxfwRh9QTmvrwOIJYGi1zbEf8DMdiGYZI4XXwm2PrDRzP4EHE0wbPMKQS+hzAN8\nzByCksr/i9tXV4Jy22PK2LYeW/9/rS8nloQxsm0PPf4744dmtsTeawC84+5Fw2lNKFkVd12pz5fg\n7mPNbBpB7+hBM7vC3R8sJ15JAxoCkrruLeAPUHzwf4ngABdvuJk1MrNsguGjlwluDznV3R+Kfb4H\nwQG0PNcB48ysS2xfWQR3k/ra3fOBL8zsqNh7fYDtCM60kzXEzFrGDtrHEfQaXgOOM7OmsftZjCAo\n812efwF9Y4kJghsDXV/BfjcS3CQlw8w+B5a7+98JSmfvWYn4pQ5SApC6bhzQxczmEdzo5KS4G3wU\nKSAoifwe8Hd3/x9wE8EBfS5B5dh3gc7l7cTdXyKYCH4stq9/E9xn+PLYR04E/mxmHxOsFjrK3deX\n+WVl+xF4AZgHPOvus9z9OYK7d80BPiUYQtpmtVRcjD8Q3ANhRiyOnsB5Fez3FYKlrcNiP8srZjYH\nGEiQ4CSNqRqopLXYKiDc/YrajaR8sVVAg9z9lFoORSJGPQARkYhSD0BEJKLUAxARiSglABGRiFIC\nEBGJKCUAEZGIUgIQEYmo/wdr9znNuHHB3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d6603c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i/tot) for i in sorted(eigen_vals, reverse = True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(1,len(var_exp)+1), var_exp, alpha = 0.5, align = 'center',\n",
    "        label = 'Individual Explained Variance')\n",
    "plt.step(range(1,len(var_exp)+1), cum_var_exp, where='mid',\n",
    "        label = 'Cumulative Explained Variance')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Evaluation Techniques\n",
    "##Try Majority Voting\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
    "    ''' A majority vote ensemble classifier\n",
    "    Params:\n",
    "        classifiers : array-like, shape = [n_classifiers]\n",
    "            Different classifiers fro the ensemble\n",
    "        \n",
    "        vote : str, {'classlabel', 'probability'}\n",
    "            Default 'classlabel'\n",
    "            If 'classlabel' the prediction is based on \n",
    "            the argmax of class labels. Else if 'probability',\n",
    "            the argmax of the sum of probabilities is used to \n",
    "            predict the class label (recommended for calibrated classifiers).\n",
    "        \n",
    "        weights : array-like, shape = [n_classifiers]\n",
    "            Optional, default: None\n",
    "            If a list of 'int' or 'float' values are provided,\n",
    "            the classifiers are weighted by importance;\n",
    "            Uses uniform weights if 'weights=None'.\n",
    "        '''\n",
    "    def __init__(self, classifiers,\n",
    "                vote = 'classlabel', weights = None):\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for \n",
    "                                 key, value  in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        ''' Fit classifiers.\n",
    "        Params:\n",
    "            X : {array-like, sparse matrix}, \n",
    "                shape = [n_samples, n_features]\n",
    "                Matrix of training samples\n",
    "            y : array-like, shape = [n_samples]\n",
    "                Vector of target class labels.\n",
    "        Returns\n",
    "            self : Object\n",
    "        '''\n",
    "        # Use LabelEncoder to ensure class labels start with 0,\n",
    "        # which is important for np.argmax, call in self.predict\n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X,\n",
    "                                       self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' Predict class labels for X.\n",
    "        Params\n",
    "            X: {array-like, sparse matrix}\n",
    "                Shape = [n_samples, n_features]\n",
    "                Matrix of training samples.\n",
    "        Returns\n",
    "            maj_vote : array-like, shape = [n_samples]\n",
    "                Predicted class labels.\n",
    "        '''\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), \n",
    "                                axis = 1)\n",
    "        else: # 'classlabel' vote\n",
    "            # Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                     for clf in self.classifiers_]).T\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                            lambda x:\n",
    "                            np.argmax(np.bincount(x, weights=self.weights)),\n",
    "                                      axis = 1,\n",
    "                                      arr = predictions)\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote                            \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        ''' Predict class probabilities for X.\n",
    "        Params:\n",
    "            X : {array-like, sparse matrix}, \n",
    "                shape = [n_samples, n_features]\n",
    "                Training vectors, where n_samples is \n",
    "                the number of samples and n_features is\n",
    "                the number of features.\n",
    "        Returns:\n",
    "        avg_proba : array-like,\n",
    "            shape = [n_samples, n_classes]\n",
    "            Weighted average probability for \n",
    "            each class per sample.\n",
    "        '''\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                            for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas,\n",
    "                              axis = 0, weights = self.weights)\n",
    "        return avg_proba\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        ''' Get classifier parameters names for GridSearch'''\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier,\n",
    "                        self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in six.iteritems(self.named_classifiers):\n",
    "                for key, value in six.iteritems(\n",
    "                        step.get_params(deep = True)):\n",
    "                    out['%s_%s' % (name, key)] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.66 (+/- 0.04) [Perceptron]\n",
      "ROC AUC: 0.76 (+/- 0.01) [LogisticRegression]\n",
      "ROC AUC: 0.75 (+/- 0.01) [Neural Net]\n",
      "ROC AUC: 0.77 (+/- 0.03) [Decision Tree]\n",
      "ROC AUC: 0.75 (+/- 0.00) [Random Forest]\n",
      "ROC AUC: 0.77 (+/- 0.01) [Majority Voting]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "names = [\"Perceptron\",\n",
    "         \"LogisticRegression\",\n",
    "         #\"Linear SVM\", \n",
    "         #\"RBF SVM\",          \n",
    "         \"Neural Net\", \n",
    "         #\"Naive Bayes\",  \n",
    "         #\"Nearest Neighbors\",\n",
    "         \"Decision Tree\", \n",
    "         \"Random Forest\",\n",
    "        \"Majority Voting\"] \n",
    "\n",
    "\n",
    "p1  = Pipeline([('scl', StandardScaler()),\n",
    "                   ('pca', PCA(n_components=60)),\n",
    "                   ('clf', Perceptron())])\n",
    "p2  = Pipeline([('scl', StandardScaler()),\n",
    "                  ('pca', PCA(n_components=60)),\n",
    "                    ('clf', LogisticRegression())])\n",
    "# p3  = Pipeline([('scl', StandardScaler()),\n",
    "#                    ('pca', PCA(n_components=5)),\n",
    "#                     ('clf', SVC(kernel=\"linear\", C=1))])\n",
    "# p4  = Pipeline([('scl', StandardScaler()),\n",
    "#                   ('pca', PCA(n_components=5)),\n",
    "#                     ('clf', SVC(kernel='rbf',gamma=2, C=1))])\n",
    "p5  = Pipeline([('scl', StandardScaler()),\n",
    "                  ('pca', PCA(n_components=50)),\n",
    "                   ('clf', MLPClassifier(hidden_layer_sizes=(100,50), alpha=1))])\n",
    "# p6  = Pipeline([('scl', StandardScaler()),\n",
    "#                   ('pca', PCA(n_components=5)),\n",
    "#                    ('clf', GaussianNB())])\n",
    "# p7  = Pipeline([('scl', StandardScaler()),\n",
    "#                   ('pca', PCA(n_components=5)),\n",
    "#                    ('clf', KNeighborsClassifier(5))])\n",
    "\n",
    "clf8  = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf',DecisionTreeClassifier(max_depth=5))])\n",
    "\n",
    "\n",
    "clf9  = Pipeline([('scl', StandardScaler()),\n",
    "                   ('clf',RandomForestClassifier(max_depth=5, n_estimators=100, max_features=1))])\n",
    "\n",
    "\n",
    "mv_clf = MajorityVoteClassifier(classifiers = [p1,p2,p5,clf8,clf9])\n",
    "                                \n",
    "clfs = [p1,p2,p5,clf8,clf9,mv_clf]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "\n",
    "for clf, name in zip(clfs, names):\n",
    "    scores = cross_val_score(estimator = clf,\n",
    "                            X = X_train,\n",
    "                            y = y_train,\n",
    "                            cv = 10,\n",
    "                            scoring = 'accuracy')\n",
    "    print('ROC AUC: %.2f (+/- %.2f) [%s]' % (scores.mean(), scores.std(), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline-1': Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False)), ('clf', Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "       n_iter=5, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "       verbose=0, warm_start=False))]),\n",
       " 'pipeline-1_clf': Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "       n_iter=5, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       " 'pipeline-1_clf__alpha': 0.0001,\n",
       " 'pipeline-1_clf__class_weight': None,\n",
       " 'pipeline-1_clf__eta0': 1.0,\n",
       " 'pipeline-1_clf__fit_intercept': True,\n",
       " 'pipeline-1_clf__n_iter': 5,\n",
       " 'pipeline-1_clf__n_jobs': 1,\n",
       " 'pipeline-1_clf__penalty': None,\n",
       " 'pipeline-1_clf__random_state': 0,\n",
       " 'pipeline-1_clf__shuffle': True,\n",
       " 'pipeline-1_clf__verbose': 0,\n",
       " 'pipeline-1_clf__warm_start': False,\n",
       " 'pipeline-1_pca': PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False),\n",
       " 'pipeline-1_pca__copy': True,\n",
       " 'pipeline-1_pca__iterated_power': 'auto',\n",
       " 'pipeline-1_pca__n_components': 100,\n",
       " 'pipeline-1_pca__random_state': None,\n",
       " 'pipeline-1_pca__svd_solver': 'auto',\n",
       " 'pipeline-1_pca__tol': 0.0,\n",
       " 'pipeline-1_pca__whiten': False,\n",
       " 'pipeline-1_scl': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-1_scl__copy': True,\n",
       " 'pipeline-1_scl__with_mean': True,\n",
       " 'pipeline-1_scl__with_std': True,\n",
       " 'pipeline-1_steps': [('scl',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('pca',\n",
       "   PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False)),\n",
       "  ('clf',\n",
       "   Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "         n_iter=5, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "         verbose=0, warm_start=False))],\n",
       " 'pipeline-2': Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False))]),\n",
       " 'pipeline-2_clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'pipeline-2_clf__C': 1.0,\n",
       " 'pipeline-2_clf__class_weight': None,\n",
       " 'pipeline-2_clf__dual': False,\n",
       " 'pipeline-2_clf__fit_intercept': True,\n",
       " 'pipeline-2_clf__intercept_scaling': 1,\n",
       " 'pipeline-2_clf__max_iter': 100,\n",
       " 'pipeline-2_clf__multi_class': 'ovr',\n",
       " 'pipeline-2_clf__n_jobs': 1,\n",
       " 'pipeline-2_clf__penalty': 'l2',\n",
       " 'pipeline-2_clf__random_state': None,\n",
       " 'pipeline-2_clf__solver': 'liblinear',\n",
       " 'pipeline-2_clf__tol': 0.0001,\n",
       " 'pipeline-2_clf__verbose': 0,\n",
       " 'pipeline-2_clf__warm_start': False,\n",
       " 'pipeline-2_pca': PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False),\n",
       " 'pipeline-2_pca__copy': True,\n",
       " 'pipeline-2_pca__iterated_power': 'auto',\n",
       " 'pipeline-2_pca__n_components': 100,\n",
       " 'pipeline-2_pca__random_state': None,\n",
       " 'pipeline-2_pca__svd_solver': 'auto',\n",
       " 'pipeline-2_pca__tol': 0.0,\n",
       " 'pipeline-2_pca__whiten': False,\n",
       " 'pipeline-2_scl': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-2_scl__copy': True,\n",
       " 'pipeline-2_scl__with_mean': True,\n",
       " 'pipeline-2_scl__with_std': True,\n",
       " 'pipeline-2_steps': [('scl',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('pca',\n",
       "   PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False)),\n",
       "  ('clf',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False))],\n",
       " 'pipeline-3': Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False)), ('clf', MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0....=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False))]),\n",
       " 'pipeline-3_clf': MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(100, 50), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " 'pipeline-3_clf__activation': 'relu',\n",
       " 'pipeline-3_clf__alpha': 1,\n",
       " 'pipeline-3_clf__batch_size': 'auto',\n",
       " 'pipeline-3_clf__beta_1': 0.9,\n",
       " 'pipeline-3_clf__beta_2': 0.999,\n",
       " 'pipeline-3_clf__early_stopping': False,\n",
       " 'pipeline-3_clf__epsilon': 1e-08,\n",
       " 'pipeline-3_clf__hidden_layer_sizes': (100, 50),\n",
       " 'pipeline-3_clf__learning_rate': 'constant',\n",
       " 'pipeline-3_clf__learning_rate_init': 0.001,\n",
       " 'pipeline-3_clf__max_iter': 200,\n",
       " 'pipeline-3_clf__momentum': 0.9,\n",
       " 'pipeline-3_clf__nesterovs_momentum': True,\n",
       " 'pipeline-3_clf__power_t': 0.5,\n",
       " 'pipeline-3_clf__random_state': None,\n",
       " 'pipeline-3_clf__shuffle': True,\n",
       " 'pipeline-3_clf__solver': 'adam',\n",
       " 'pipeline-3_clf__tol': 0.0001,\n",
       " 'pipeline-3_clf__validation_fraction': 0.1,\n",
       " 'pipeline-3_clf__verbose': False,\n",
       " 'pipeline-3_clf__warm_start': False,\n",
       " 'pipeline-3_pca': PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False),\n",
       " 'pipeline-3_pca__copy': True,\n",
       " 'pipeline-3_pca__iterated_power': 'auto',\n",
       " 'pipeline-3_pca__n_components': 100,\n",
       " 'pipeline-3_pca__random_state': None,\n",
       " 'pipeline-3_pca__svd_solver': 'auto',\n",
       " 'pipeline-3_pca__tol': 0.0,\n",
       " 'pipeline-3_pca__whiten': False,\n",
       " 'pipeline-3_scl': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-3_scl__copy': True,\n",
       " 'pipeline-3_scl__with_mean': True,\n",
       " 'pipeline-3_scl__with_std': True,\n",
       " 'pipeline-3_steps': [('scl',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('pca',\n",
       "   PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False)),\n",
       "  ('clf',\n",
       "   MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "          beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "          hidden_layer_sizes=(100, 50), learning_rate='constant',\n",
       "          learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "          nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "          shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "          verbose=False, warm_start=False))],\n",
       " 'pipeline-4': Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=None, splitter='best'))]),\n",
       " 'pipeline-4_clf': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=None, splitter='best'),\n",
       " 'pipeline-4_clf__class_weight': None,\n",
       " 'pipeline-4_clf__criterion': 'gini',\n",
       " 'pipeline-4_clf__max_depth': 5,\n",
       " 'pipeline-4_clf__max_features': None,\n",
       " 'pipeline-4_clf__max_leaf_nodes': None,\n",
       " 'pipeline-4_clf__min_impurity_split': 1e-07,\n",
       " 'pipeline-4_clf__min_samples_leaf': 1,\n",
       " 'pipeline-4_clf__min_samples_split': 2,\n",
       " 'pipeline-4_clf__min_weight_fraction_leaf': 0.0,\n",
       " 'pipeline-4_clf__presort': False,\n",
       " 'pipeline-4_clf__random_state': None,\n",
       " 'pipeline-4_clf__splitter': 'best',\n",
       " 'pipeline-4_scl': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-4_scl__copy': True,\n",
       " 'pipeline-4_scl__with_mean': True,\n",
       " 'pipeline-4_scl__with_std': True,\n",
       " 'pipeline-4_steps': [('scl',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('clf',\n",
       "   DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               presort=False, random_state=None, splitter='best'))],\n",
       " 'pipeline-5': Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=5, max_features=1, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "             verbose=0, warm_start=False))]),\n",
       " 'pipeline-5_clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=5, max_features=1, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "             verbose=0, warm_start=False),\n",
       " 'pipeline-5_clf__bootstrap': True,\n",
       " 'pipeline-5_clf__class_weight': None,\n",
       " 'pipeline-5_clf__criterion': 'gini',\n",
       " 'pipeline-5_clf__max_depth': 5,\n",
       " 'pipeline-5_clf__max_features': 1,\n",
       " 'pipeline-5_clf__max_leaf_nodes': None,\n",
       " 'pipeline-5_clf__min_impurity_split': 1e-07,\n",
       " 'pipeline-5_clf__min_samples_leaf': 1,\n",
       " 'pipeline-5_clf__min_samples_split': 2,\n",
       " 'pipeline-5_clf__min_weight_fraction_leaf': 0.0,\n",
       " 'pipeline-5_clf__n_estimators': 100,\n",
       " 'pipeline-5_clf__n_jobs': 1,\n",
       " 'pipeline-5_clf__oob_score': False,\n",
       " 'pipeline-5_clf__random_state': None,\n",
       " 'pipeline-5_clf__verbose': 0,\n",
       " 'pipeline-5_clf__warm_start': False,\n",
       " 'pipeline-5_scl': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-5_scl__copy': True,\n",
       " 'pipeline-5_scl__with_mean': True,\n",
       " 'pipeline-5_scl__with_std': True,\n",
       " 'pipeline-5_steps': [('scl',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('clf',\n",
       "   RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=5, max_features=1, max_leaf_nodes=None,\n",
       "               min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "               verbose=0, warm_start=False))]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'pipeline-1_clf__alpha': [0.001,0.1,1.0, 10.0],\n",
    "          'pipeline-1_clf__penalty': ['l1','l2'],\n",
    "          #'pipeline-2_clf__C':[0.001,0.1,1.0,10.0,100.0],\n",
    "          'pipeline-2_clf__penalty': ['l1','l2'],\n",
    "          'pipeline-3_clf__alpha': [0.001,0.1,1.0, 10.0],\n",
    "          #'pipeline-3_clf__C':[0.001,0.1,100.0],\n",
    "          'pipeline-3_clf__hidden_layer_sizes': [(100, 50),(100,100)],\n",
    "          'pipeline-3_clf__learning_rate_init':[0.001,0.01,0.1,1.0,10.00]    \n",
    "         }\n",
    "\n",
    "gs = GridSearchCV(estimator = mv_clf,\n",
    "                 param_grid = params,\n",
    "                 scoring = 'accuracy',\n",
    "                 cv = 3,\n",
    "                 n_jobs = -1)\n",
    "gs = gs.fit(X_train, y_train) \n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.930 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.930 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.927 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.928 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.933 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.927 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.920 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.920 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.939 +/- 0.01 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.936 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.941 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.937 +/- 0.01 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.931 +/- 0.01 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.932 +/- 0.01 {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.933 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.933 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.935 +/- 0.01 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.931 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.925 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.925 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.937 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.941 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.939 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.935 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.935 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.936 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.940 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.935 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.936 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.935 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.935 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.939 +/- 0.01 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.943 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.937 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.942 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.933 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.933 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.937 +/- 0.01 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.933 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.935 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.937 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.935 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.940 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.936 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.937 +/- 0.01 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.933 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.933 +/- 0.01 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.931 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.939 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.938 +/- 0.01 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.940 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.937 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.940 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.938 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.934 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.936 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.941 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.935 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.933 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n",
      "0.936 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)}\n",
      "0.931 +/- 0.00 {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n"
     ]
    }
   ],
   "source": [
    "for params, mean_score, scores in gs.grid_scores_:\n",
    "    print('%.3f +/- %.2f %r' % (mean_score, scores.std()/2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.92963, std: 0.00693, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.92963, std: 0.00519, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.92667, std: 0.00090, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.92844, std: 0.00473, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93258, std: 0.00262, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.92667, std: 0.00474, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.92017, std: 0.00637, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.91957, std: 0.00455, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93909, std: 0.01179, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93613, std: 0.00507, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.94145, std: 0.00958, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93732, std: 0.01415, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93791, std: 0.00733, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93377, std: 0.00807, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93140, std: 0.01180, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93199, std: 0.01058, params: {'pipeline-2_clf__C': 0.001, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93258, std: 0.00512, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93436, std: 0.00878, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93258, std: 0.00512, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93495, std: 0.01135, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93377, std: 0.00695, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93140, std: 0.00519, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.92549, std: 0.00445, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.92549, std: 0.00643, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93672, std: 0.00875, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93791, std: 0.00530, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.94145, std: 0.00507, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93850, std: 0.00364, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93850, std: 0.00803, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93909, std: 0.00751, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93495, std: 0.00462, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93436, std: 0.00435, params: {'pipeline-2_clf__C': 0.1, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93495, std: 0.00753, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93791, std: 0.00667, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93613, std: 0.00886, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93850, std: 0.00662, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.94027, std: 0.00804, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93495, std: 0.00509, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93554, std: 0.00452, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93495, std: 0.00518, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93495, std: 0.00445, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93909, std: 0.01018, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93436, std: 0.00636, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.94264, std: 0.00720, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93732, std: 0.00472, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.94205, std: 0.00593, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93318, std: 0.00476, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93436, std: 0.00154, params: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93318, std: 0.00832, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93672, std: 0.01233, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93850, std: 0.00424, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93318, std: 0.00692, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93495, std: 0.00692, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93672, std: 0.00424, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93436, std: 0.00638, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93495, std: 0.00831, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.94027, std: 0.00674, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93613, std: 0.00725, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93672, std: 0.01456, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93258, std: 0.00387, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93258, std: 0.01010, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93791, std: 0.00809, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93140, std: 0.00232, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93436, std: 0.00636, params: {'pipeline-2_clf__C': 10.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93909, std: 0.00719, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93850, std: 0.01053, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93850, std: 0.00675, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.94027, std: 0.00936, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93791, std: 0.00758, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93672, std: 0.00662, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93436, std: 0.00733, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93968, std: 0.00667, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l1', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93850, std: 0.00688, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93377, std: 0.00312, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.001, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93613, std: 0.00958, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.94086, std: 0.00610, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93495, std: 0.00938, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93258, std: 0.00809, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 1.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)},\n",
       " mean: 0.93554, std: 0.00607, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 50)},\n",
       " mean: 0.93140, std: 0.00519, params: {'pipeline-2_clf__C': 100.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 10.0, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'pipeline-2_clf__C': 1.0, 'pipeline-2_clf__penalty': 'l2', 'pipeline-3_clf__alpha': 0.1, 'pipeline-3_clf__hidden_layer_sizes': (100, 100)}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters: %s' % gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f' % gs.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
